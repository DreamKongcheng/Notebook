<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../../../img/favicon.ico">
        <title>Lab-3 基于CUDA对GEMM的优化 - 我的第一个站点</title>
        <link href="../../../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../../../..">我的第一个站点</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href="../../../.." class="nav-link">Welcome to MkDocs</a>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">ZJU CS <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../" class="dropdown-item">ZJU CS 课程</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">DigitalDesign</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../DigitalDesign/" class="dropdown-item">[大二秋冬] 数字逻辑设计 | Digital Design</a>
</li>
            
<li>
    <a href="../../../DigitalDesign/Chap01/" class="dropdown-item">Chap 1 Digital Systems and Information</a>
</li>
            
<li>
    <a href="../../../DigitalDesign/Chap02/" class="dropdown-item">Chap 2 Combinational Logic Circuits</a>
</li>
            
<li>
    <a href="../../../DigitalDesign/Chap03/" class="dropdown-item">Chap 3 Combinational Logic Design</a>
</li>
            
<li>
    <a href="../../../DigitalDesign/Chap04/" class="dropdown-item">Chap 4 Sequential Circuits</a>
</li>
            
<li>
    <a href="../../../DigitalDesign/Chap05/" class="dropdown-item">Chap 5 Digital Hardware Implementation</a>
</li>
            
<li>
    <a href="../../../DigitalDesign/Chap06/" class="dropdown-item">Chap 6 Registers & Register Transfers</a>
</li>
            
<li>
    <a href="../../../DigitalDesign/Chap07/" class="dropdown-item">Chap 7 Memory Basics</a>
</li>
            
<li>
    <a href="../../../DigitalDesign/glossary/" class="dropdown-item">词汇表</a>
</li>
            
<li>
    <a href="../../../DigitalDesign/learnskill/" class="dropdown-item">学习思路以及资源</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Discrete math</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../Discrete%20math/" class="dropdown-item">离散数学</a>
</li>
            
<li>
    <a href="../../../Discrete%20math/note/" class="dropdown-item">摘要</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">FDS</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../../FDS/" class="dropdown-item">Index</a>
</li>
            
<li>
    <a href="../../../FDS/algorithm/" class="dropdown-item">算法分析</a>
</li>
            
<li>
    <a href="../../../FDS/exam/" class="dropdown-item">历年卷</a>
</li>
            
<li>
    <a href="../../../FDS/graph/" class="dropdown-item">图论</a>
</li>
            
<li>
    <a href="../../../FDS/hash/" class="dropdown-item">散列（哈希）</a>
</li>
            
<li>
    <a href="../../../FDS/heap/" class="dropdown-item">优先队列（堆）</a>
</li>
            
<li>
    <a href="../../../FDS/homework/" class="dropdown-item">作业要点</a>
</li>
            
<li>
    <a href="../../../FDS/set/" class="dropdown-item">并查集</a>
</li>
            
<li>
    <a href="../../../FDS/sort/" class="dropdown-item">排序</a>
</li>
            
<li>
    <a href="../../../FDS/tree/" class="dropdown-item">树</a>
</li>
            
<li>
    <a href="../../../FDS/%E6%95%B0%E7%BB%84%E4%B8%8E%E9%93%BE%E8%A1%A8/" class="dropdown-item">数组与链表</a>
</li>
            
<li>
    <a href="../../../FDS/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/" class="dropdown-item">栈和队列</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">HPC</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../" class="dropdown-item">ZJUSCT</a>
</li>
            
<li>
    <a href="../../AIPP/" class="dropdown-item">并行计算设计导论</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Class</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../class/" class="dropdown-item">note of class</a>
</li>
            
<li>
    <a href="../../class/L1/" class="dropdown-item">7月4日 计算机体系结构和高性能计算基础</a>
</li>
            
<li>
    <a href="../../class/L2/" class="dropdown-item">7月5日 高性能计算方法论（HPC）</a>
</li>
            
<li>
    <a href="../../class/L3/" class="dropdown-item">7月6日 集群软硬件以及运维基础</a>
</li>
            
<li>
    <a href="../../class/L4/" class="dropdown-item">7月8日 向量化并行计算基础</a>
</li>
            
<li>
    <a href="../../class/L5/" class="dropdown-item">7月9日 GPU (Graphic Processing Unit)</a>
</li>
            
<li>
    <a href="../../class/L6/" class="dropdown-item">7月10日 OpenMP</a>
</li>
            
<li>
    <a href="../../class/L7/" class="dropdown-item">7月11号 机器学习（Machine Learning)</a>
</li>
            
<li>
    <a href="../../class/L8/" class="dropdown-item">高性能计算高级话术</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Homework</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../lab1/" class="dropdown-item">Lab-1</a>
</li>
            
<li>
    <a href="../lab2.5/" class="dropdown-item">Lab-2</a>
</li>
            
<li>
    <a href="../lab2/" class="dropdown-item">Lab2 向量化计算</a>
</li>
            
<li>
    <a href="./" class="dropdown-item active">Lab-3 基于CUDA对GEMM的优化</a>
</li>
            
<li>
    <a href="../lab4/" class="dropdown-item">Lab-4 PCG算法在OMP和MPI下的优化</a>
</li>
            
<li>
    <a href="../lab5/" class="dropdown-item">Lab-5 AI相关</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../lab2/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../lab4/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#lab-3-cudagemm" class="nav-link">Lab-3 基于CUDA对GEMM的优化</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#lab-description" class="nav-link">Lab Description</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#introduction-knowledge" class="nav-link">Introduction Knowledge(可以跳过不看)</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#lab-design-test-result" class="nav-link">Lab Design &amp; Test Result</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#discussion" class="nav-link">Discussion</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#bonus" class="nav-link">Bonus</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="lab-3-cudagemm">Lab-3 基于CUDA对GEMM的优化</h1>
<div class="toc">
<ul>
<li><a href="#lab-3-cudagemm">Lab-3 基于CUDA对GEMM的优化</a><ul>
<li><a href="#lab-description">Lab Description</a></li>
<li><a href="#introduction-knowledge">Introduction Knowledge(可以跳过不看)</a></li>
<li><a href="#lab-design-test-result">Lab Design &amp; Test Result</a><ul>
<li><a href="#addercudakernel">AdderCudaKernel</a></li>
<li><a href="#shared-memory">Shared Memory</a></li>
<li><a href="#_1">循环展开</a></li>
<li><a href="#_2">测试结果</a></li>
</ul>
</li>
<li><a href="#discussion">Discussion</a></li>
<li><a href="#bonus">Bonus</a></li>
</ul>
</li>
</ul>
</div>
<h2 id="lab-description">Lab Description</h2>
<hr />
<p>具体描述请见{实验手册}(https://zjusct.pages.zjusct.io/summer-course-2023/HPC101-Labs-2023/Lab3-Cuda/)</p>
<p>通用矩阵乘法（<a href="https://en.wikipedia.org/wiki/General_matrix_multiply">General matrix multiply</a>, GEMM）是 BLAS 中经典的子程序之一。[2] 作为当今科学计算最常见的计算任务之一，GEMM 需要实现一个非常高效的矩阵乘法。优化 GEMM 也是 HPC 界非常基础的任务。</p>
<p>本次实验需要你使用 CUDA 完成一个高性能 GEMM 实现。</p>
<p><strong>Bonus：</strong>另外本次实验提供的 GPU 上，包含上述提及的 Tensor Core 模块。合理的使用它能够进一步加速卷积的计算。在 Cuda 9.0 之后，你可以使用内嵌 <code>PTX</code> 汇编或者 CUDA 的 C++ 扩展 <code>nvcuda::wmma</code> 的方式来显式地调用 Tensor Core 来进行计算。</p>
<h2 id="introduction-knowledge">Introduction Knowledge(可以跳过不看)</h2>
<hr />
<ol>
<li>
<p>CUDA使用：建议上官网。至于lab中提到的不同API的区别，可见<a href="https://blog.csdn.net/weixin_44966641/article/details/124500258">博客</a></p>
</li>
<li>
<p>关于高性能计算矩阵乘法（GEMM）的<a href="https://www.cs.utexas.edu/users/pingali/CS378/2008sp/papers/gotoPaper.pdf">说明</a>. <a href="https://zhuanlan.zhihu.com/p/280771849#:~:text=gotoBLAS中的GEMM实现就使用了分块算法。 从图中我们可以看到三种处理方法。,第一种是将A和B矩阵分块，第二种方法是将C和B矩阵分块，第三种方法是将C和A矩阵分块。 GEMM的子任务是GEPP或GEMP；最小粒度的任务是GEBP或GEPB或点乘。">CS217</a></p>
</li>
<li>
<p>Introduction to shared memory.(<a href="https://zhuanlan.zhihu.com/p/597529982">link</a>) </p>
</li>
<li>
<p>一个Github上不同优化方法的<a href="https://github.com/mrzhuzhe/riven/tree/main/cuda_test">对比</a></p>
</li>
<li>
<p>CUDA自己对shared memory 的使用的示例<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html">3.2.4 GEMM</a></p>
</li>
<li>
<p>有些知识感觉问gpt获取的速度会更快，但是具体的细节还是在官网上查阅更好（<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-hierarchy">官网</a>的知识介绍非常全）\</p>
</li>
</ol>
<h2 id="lab-design-test-result">Lab Design &amp; Test Result</h2>
<hr />
<pre><code class="language-c">/// \brief Let A to be A + B.
__global__ void AdderCudaKernel(double *__restrict__ a,
                                  const double *__restrict__ b)
{
    // const int i = blockIdx.x * block_size + threadIdx.x;
    // const int j = blockIdx.y * block_size + threadIdx.y;
    // if (i &lt; size &amp;&amp; j &lt; size)
    // {
    //   a(i, j) += b(i, j);
    // }
    __shared__ double shared_a[block_size][block_size];
    __shared__ double shared_b[block_size][block_size];

    int i = blockIdx.x * block_size + threadIdx.x;
    int j = blockIdx.y * block_size + threadIdx.y;

    if (i &lt; size &amp;&amp; j &lt; size) {
        shared_a[threadIdx.x][threadIdx.y] = a[i * size + j];
        shared_b[threadIdx.x][threadIdx.y] = b[i * size + j];
        __syncthreads();

        shared_a[threadIdx.x][threadIdx.y] += shared_b[threadIdx.x][threadIdx.y];
        __syncthreads();

        a(i,j) = shared_a[threadIdx.x][threadIdx.y];
    }
}

/// \brief Do Matrix Multiplication on GPU.
__global__ void MultipleCudaKernel(const double *__restrict__ a, 
                                   const double *__restrict__ b, 
                                   double *__restrict__ result) 
{     
    // Get the index of the current thread
    const int row = blockIdx.y * blockDim.y + threadIdx.y;
    const int col = blockIdx.x * blockDim.x + threadIdx.x;
    const int block_num = (size + block_size - 1) / block_size;

    // Define shared memory
    alignas(32) __shared__ double shared_a[block_size][block_size];
    alignas(32) __shared__ double shared_b[block_size][block_size];

    // Perform matrix multiplication operation
    double sum = 0.0f;
    for (int i = 0; i &lt; block_num; i++) {
        // Load data from A and B into shared memory
        int idx_a = row * size + i * block_size + threadIdx.x;
        int idx_b = (i * block_size + threadIdx.y) * size + col;
        shared_a[threadIdx.y][threadIdx.x] = (row &lt; size &amp;&amp; (i * block_size + threadIdx.x) &lt; size) ? a[idx_a] : 0.0f;
        shared_b[threadIdx.y][threadIdx.x] = ((i * block_size + threadIdx.y) &lt; size &amp;&amp; col &lt; size) ? b[idx_b] : 0.0f;
         // Synchronize to make sure the matrices are loaded before starting the computation
        __syncthreads();

        #pragma unroll
        for (int j = 0;  j &lt; block_size; j ++) {
            // sum = fma(shared_a[threadIdx.y][j], shared_b[j][threadIdx.x], sum);
            // sum = fma(shared_a[threadIdx.y][j + 1], shared_b[j + 1][threadIdx.x], sum);
            // sum = fma(shared_a[threadIdx.y][j + 2], shared_b[j + 2][threadIdx.x], sum);
            // sum = fma(shared_a[threadIdx.y][j + 3], shared_b[j + 3][threadIdx.x], sum);
            sum += shared_a[threadIdx.y][j] * shared_b[j][threadIdx.x];
        }
        // Synchronize to make sure the computation is done before loading the next sub-matrix
        __syncthreads();
    }

    if(row &lt; size &amp;&amp; col &lt; size) {
        // Write the result back to result_kernel
        result(row, col) = sum;
    }
}
</code></pre>
<p><strong>Baseline分析：</strong>对于baseline而言，其速度慢的原因一方面是只能串行线性进行计算；另一方面在于每次循环都要对主存进行数据的读写。故我们要针对以上的内容进行优化。</p>
<p><strong>优化策略：</strong>共享内存，内存对齐，循环展开（编译器会自动实现）、fma等</p>
<h3 id="addercudakernel">AdderCudaKernel</h3>
<p><img alt="" src="F:\Note of computer\docs\ZJU_CS\超算\homework\graph\Snipaste_2023-07-23_21-06-03.png" /></p>
<p>第一个是常规的<strong>AdderCudaKernel</strong>的测试，第二个是使用共享内存的测试时间，由于每次测试具有随机以及不稳定性，针对这种情况我分析可能是<code>__syncthreads()；</code>导致停顿的时间。</p>
<h3 id="shared-memory">Shared Memory</h3>
<p>共享内存是测试中加速的主要原因，我们其中使用内存对齐的方式能够有些许加速。</p>
<p>在测试中我们发现共享内存的大小是<code>0xc000</code>,因此我们将blocksize的大小设置为16比较合适。</p>
<h3 id="_1">循环展开</h3>
<p>这是一个比较常见的优化手段，但是因为我们使用的是O3优化，以及<code>#pragma unroll</code>,提示编译器，故在我的测试中发现不用自己手写循环展开的优化。</p>
<p>其中<code>fma</code> 值得我们学习，这是CUDA本身自带的一种加速指令。</p>
<h3 id="_2">测试结果</h3>
<p><img alt="" src="F:\Note of computer\docs\ZJU_CS\超算\homework\graph\Snipaste_2023-07-23_21-08-27.png" /></p>
<p><img alt="" src="F:\Note of computer\docs\ZJU_CS\超算\homework\graph\Snipaste_2023-07-23_21-58-40.png" /></p>
<p>故加速比为<strong>0.94818</strong></p>
<h2 id="discussion">Discussion</h2>
<hr />
<p>本次lab教会了我如何使用CUDA进行GPU编程，在整个编程过程中，基本阅读了官方文档，并且了解了thread和warp编程思想，以及结合课上的知识，深入理解了内存的内部构造以及NVIDA显卡的自身结构特性，在此基础上进行了优化。</p>
<h2 id="bonus">Bonus</h2>
<p>关于Bonus，虽然自己没有完整做出来用tensor core的计算方法，但自己也在这个上面投入了比较多的精力，最后根据我的测试应该问题还是出现在了block和grid的数目配置上，因此导致计算结果有误。我的代码如下：</p>
<pre><code class="language-c">dim3 grid((size + block_size * WMMA_M - 1) / (block_size * WMMA_M),
            (size + block_size * WMMA_N - 1) / (block_size * WMMA_N));
dim3 block(block_size, block_size);

const int WMMA_M = 8;
const int WMMA_N = 8;
const int WMMA_K = 4;

/// \brief Do Matrix Multiplication on GPU.
__global__ void MultipleCudaKernel(const double *__restrict__ a, 
                                   const double *__restrict__ b, 
                                   double *__restrict__ result) 
{
    // Tile using a 2D grid
    const int warpM = (blockIdx.x * blockDim.x + threadIdx.x) / warpSize;
    const int warpN = (blockIdx.y * blockDim.y + threadIdx.y);

    // Declare the fragments
    using namespace nvcuda;
    wmma::fragment&lt;wmma::matrix_a, WMMA_M, WMMA_N, WMMA_K, double, wmma::col_major&gt; a_frag;
    wmma::fragment&lt;wmma::matrix_b, WMMA_M, WMMA_N, WMMA_K, double, wmma::col_major&gt; b_frag;
    wmma::fragment&lt;wmma::accumulator, WMMA_M, WMMA_N, WMMA_K, double&gt; acc_frag;
    //initialize
    wmma::fill_fragment(acc_frag, 0.0);

    // Loop over size
    for (int i = 0; i &lt; size; i += WMMA_K) {
        int aRow = warpM * WMMA_M;
        int aCol = i;

        int bRow = i;
        int bCol = warpN * WMMA_N;

        // Bounds checking
        if (aRow &lt; size &amp;&amp; aCol &lt; size &amp;&amp; bRow &lt; size &amp;&amp; bCol &lt; size) {
          // Load the inputs
          wmma::load_matrix_sync(a_frag, a + aRow + aCol * size, size);
          wmma::load_matrix_sync(b_frag, b + bRow + bCol * size, size);

          // Perform the matrix multiplication
          wmma::mma_sync(acc_frag, a_frag, b_frag, acc_frag);
        }
    }

    int cRow = warpM * WMMA_M;
    int cCol = warpN * WMMA_N;
    // Store the output
    if (cRow &lt; size &amp;&amp; cCol &lt; size) {
    wmma::store_matrix_sync(result + cRow + cCol * size, acc_frag, size, wmma::mem_col_major);
    }
}
</code></pre>
<p><img alt="" src="../graph/Snipaste_2023-08-02_15-43-20.png" /></p>
<p><strong>结论：</strong>通过tensor core的计算，我们能很大程度上避免冲突并且加速计算。通过printf大法我看出我的计算结果与正确的计算结果相差了大约4倍左右，但不太理解自己错在了哪里？如果可以的话希望超算队的学长可以帮忙指出。</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../../../../js/jquery-3.6.0.min.js"></script>
        <script src="../../../../js/bootstrap.min.js"></script>
        <script>
            var base_url = "../../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../../js/base.js"></script>
        <script src="../../../../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
